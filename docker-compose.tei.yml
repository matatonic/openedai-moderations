services:
  text-embeddings-inference:
    # See: https://github.com/huggingface/text-embeddings-inference/pkgs/container/text-embeddings-inference
    image: ghcr.io/huggingface/text-embeddings-inference:1.2
    #image: ghcr.io/huggingface/text-embeddings-inference:cpu-1.2
    env_file:
      - tei.env
    container_name: text-embeddings-inference
    restart: unless-stopped
    ports:
      - 8080:80
    volumes:
      - ./embedding_data:/data
    # Below can be removed if not using GPU
    runtime: nvidia
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              #device_ids: ['0', '1'] # Select a gpu, or
              count: all
              capabilities: [gpu]
